# Environment variables for EasyAccountsGPU
# Copy this to .env and fill in your actual values

# Hugging Face Token (required for Llama-3.1-8B access)
HUGGING_FACE_TOKEN=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

# Nanonets API - NOT NEEDED for GPU service (uses local extraction only)
# GPU service uses DocumentExtractor with cpu=True (local mode)
# Backend handles cloud extraction separately if needed

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=false

# Model Configuration
TRANSFORMERS_CACHE=/app/models
HF_HOME=/app/models
TORCH_HOME=/app/models

# GPU Configuration
CUDA_VISIBLE_DEVICES=0

# Logging
LOG_LEVEL=INFO
PYTHONUNBUFFERED=1

# RunPod Specific
RUNPOD_AI_API_KEY=your_runpod_api_key_here
RUNPOD_ENDPOINT_ID=your_endpoint_id_here